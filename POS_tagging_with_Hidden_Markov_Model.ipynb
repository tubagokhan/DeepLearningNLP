{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMGc5kDk2r7bOYll8E24dQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tubagokhan/DeepLearningNLPFoundations/blob/main/POS_tagging_with_Hidden_Markov_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://wisdomml.in/hidden-markov-model-hmm-in-nlp-python/)"
      ],
      "metadata": {
        "id": "B96cuwcSEOTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring Treebank Tagged Corpus"
      ],
      "metadata": {
        "id": "ldGlMHM26KsB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk5THX2Q51Cy"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "import nltk, re, pprint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pprint, time\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "#download the treebank corpus from nltk\n",
        "nltk.download('treebank')\n",
        "\n",
        "# reading the Treebank tagged sentences\n",
        "wsj = list(nltk.corpus.treebank.tagged_sents())\n",
        "\n",
        "# first tagged sentence\n",
        "print(wsj[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "LvE5omZG6Z_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into train and test\n",
        "random.seed(1234)\n",
        "train_set, test_set = train_test_split(wsj,test_size=0.3)\n",
        "print(len(train_set))\n",
        "print(len(test_set))\n",
        "print(train_set[:1])"
      ],
      "metadata": {
        "id": "OiXRBunC6dhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting list of tagged words\n",
        "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
        "len(train_tagged_words)"
      ],
      "metadata": {
        "id": "90cU9uA46xOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens \n",
        "tokens = [pair[0] for pair in train_tagged_words]\n",
        "# vocabulary\n",
        "V = set(tokens)\n",
        "print(\"Total vocabularies: \",len(V))\n",
        "# number of tags\n",
        "T = set([pair[1] for pair in train_tagged_words])\n",
        "print(\"Total tags: \",len(T))"
      ],
      "metadata": {
        "id": "dK1LIRrV68p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'LS': list item marker\n",
        "'PDT': predeterminer\n",
        "'SYM': Symbol\n",
        "'DT': determiner\n",
        "'-RRB-': comporative adv\n",
        "'VBZ': verb 3sg pres\n",
        "'EX': existential ‘there’\n",
        "'VBP': verb non-3sg-pr\n",
        "':': \n",
        "'WP': wh-pronoun\n",
        "'TO': to\n",
        "'MD': modal\n",
        "'NNPS': proper noun: plu\n",
        "'IN': preposition\n",
        "'VBD': verb past tense\n",
        "'PRP': personal pronoun\n",
        "':': \n",
        "'VBN': verb past participle\n",
        "'VBG': verb gerund\n",
        "'$': \n",
        "'-NONE-': \n",
        "'UH': interjection\n",
        "'PRP$': possess: pronoun\n",
        "'WDT': wh-determ.\n",
        "'JJS': superlative adj\n",
        "'POS': possessive ending\n",
        "'#': \n",
        "\"''\": \n",
        "'NNS': noun: plural\n",
        "'JJR': comparative adj\n",
        "'FW': foreign word\n",
        "'CD': cardinal number\n",
        "'VB': verb base\n",
        "'-LRB-': \n",
        "'RB': adverb\n",
        "'NN': sing or mass noun\n",
        "'``':\n",
        "'WP$': wh-posses\n",
        "'NNP': proper noun: sing.\n",
        "'WRB': wh-adverb\n",
        "'JJ': adjective\n",
        "'RBS': superlative adv\n",
        "'RBR': comparative adv\n",
        "'RP': adverb\n",
        "'CC': coord. Conj.\n",
        "'.'\n"
      ],
      "metadata": {
        "id": "Qq6D6JCoBZQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Emission probabilities"
      ],
      "metadata": {
        "id": "1g4YV1uE7PWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# computing P(w/t) and storing in T x V matrix\n",
        "t = len(T)\n",
        "v = len(V)\n",
        "w_given_t = np.zeros((t, v))\n",
        "\n",
        "# compute word given tag: Emission Probability\n",
        "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
        "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
        "    count_tag = len(tag_list)\n",
        "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
        "    count_w_given_tag = len(w_given_tag_list)\n",
        "    \n",
        "    return (count_w_given_tag, count_tag)\n",
        "\n",
        "# examples\n",
        "\n",
        "# large\n",
        "print(\"\\n\", \"large\")\n",
        "print(word_given_tag('large', 'JJ')) ## JJ adjective\n",
        "print(word_given_tag('large', 'VB')) ## VB verb base\n",
        "print(word_given_tag('large', 'NN'), \"\\n\") ## NN sing or mass noun\n",
        "\n",
        "# will\n",
        "print(\"\\n\", \"will\")\n",
        "print(word_given_tag('will', 'MD')) ## MD modal\n",
        "print(word_given_tag('will', 'NN'))\n",
        "print(word_given_tag('will', 'VB'))\n",
        "\n",
        "# book\n",
        "print(\"\\n\", \"book\")\n",
        "print(word_given_tag('book', 'NN'))\n",
        "print(word_given_tag('book', 'VB'))"
      ],
      "metadata": {
        "id": "zrs5qF0P7He4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transition Probabilities"
      ],
      "metadata": {
        "id": "ii3tL3AH8GVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
        "\n",
        "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
        "    tags = [pair[1] for pair in train_bag]\n",
        "    count_t1 = len([t for t in tags if t==t1])\n",
        "    count_t2_t1 = 0\n",
        "    for index in range(len(tags)-1):\n",
        "        if tags[index]==t1 and tags[index+1] == t2:\n",
        "            count_t2_t1 += 1\n",
        "    return (count_t2_t1, count_t1)\n",
        "\n",
        "# examples\n",
        "print(t2_given_t1(t2='NNP', t1='JJ')) ## NNP proper noun singular , JJ adjective\n",
        "print(t2_given_t1('NN', 'JJ')) ## NN sing or mass noun, JJ adjective\n",
        "print(t2_given_t1('NN', 'DT')) ## NN sing or mass noun, DT determiner\n",
        "print(t2_given_t1('NNP', 'VB')) ## NNP proper noun singular, VB verb base\n",
        "print(t2_given_t1(',', 'NNP'))\n",
        "print(t2_given_t1('PRP', 'PRP')) ## PRP personel pronoun\n",
        "print(t2_given_t1('VBG', 'NNP')) ## VBG verb gerund, NNP proper noun singular"
      ],
      "metadata": {
        "id": "4jwEASL_8JaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating t x t transition matrix of tags\n",
        "# each column is t2, each row is t1\n",
        "# thus M(i, j) represents P(tj given ti)\n",
        "\n",
        "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
        "for i, t1 in enumerate(list(T)):\n",
        "    for j, t2 in enumerate(list(T)): \n",
        "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
        "\n",
        "tags_matrix # transition matrix"
      ],
      "metadata": {
        "id": "l_ThLZuK9D24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tags_matrix)"
      ],
      "metadata": {
        "id": "4gbk3ci29o7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the matrix to a df for better readability\n",
        "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))\n",
        "tags_df"
      ],
      "metadata": {
        "id": "LFXbvWp_CF-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# heatmap of tags matrix\n",
        "# T(i, j) means P(tag j given tag i)\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(tags_df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g7kSOz9vCNLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frequent tags\n",
        "# filter the df to get P(t2, t1) > 0.5\n",
        "tags_frequent = tags_df[tags_df>0.5]\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(tags_frequent)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wqc9_3oGCuc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Viterbi Algorithm"
      ],
      "metadata": {
        "id": "GL-qTeoyC6n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Viterbi Heuristic\n",
        "def Viterbi(words, train_bag = train_tagged_words):\n",
        "    state = []\n",
        "    T = list(set([pair[1] for pair in train_bag]))\n",
        "    \n",
        "    for key, word in enumerate(words):\n",
        "        #initialise list of probability column for a given observation\n",
        "        p = [] \n",
        "        for tag in T:\n",
        "            if key == 0:\n",
        "                transition_p = tags_df.loc['.', tag]\n",
        "            else:\n",
        "                transition_p = tags_df.loc[state[-1], tag]\n",
        "                \n",
        "            # compute emission and state probabilities\n",
        "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
        "            state_probability = emission_p * transition_p    \n",
        "            p.append(state_probability)\n",
        "            \n",
        "        pmax = max(p)\n",
        "        # getting state for which probability is maximum\n",
        "        state_max = T[p.index(pmax)] \n",
        "        state.append(state_max)\n",
        "    return list(zip(words, state))"
      ],
      "metadata": {
        "id": "8O-ep1F4C5go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating on Test Set"
      ],
      "metadata": {
        "id": "wrRUK63_DKro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running on entire test dataset would take more than 3-4hrs. \n",
        "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
        "\n",
        "random.seed(1234)\n",
        "\n",
        "# choose random 5 sents\n",
        "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
        "\n",
        "# list of sents\n",
        "test_run = [test_set[i] for i in rndom]\n",
        "\n",
        "# list of tagged words\n",
        "test_run_base = [tup for sent in test_run for tup in sent]\n",
        "\n",
        "# list of untagged words\n",
        "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
        "test_run"
      ],
      "metadata": {
        "id": "OF9hkX5uDKPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tagging the test sentences\n",
        "start = time.time()\n",
        "tagged_seq = Viterbi(test_tagged_words)\n",
        "end = time.time()\n",
        "difference = end-start\n",
        "print(\"Time taken in seconds: \", difference)\n",
        "print(tagged_seq)"
      ],
      "metadata": {
        "id": "iAylnx6cDmhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
        "accuracy = len(check)/len(tagged_seq)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "m6VgziIUDsiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Testing\n",
        "sentence_test = 'Twitter is the best networking social site. Man is a social animal. Data science is an emerging field. Data science jobs are high in demand.'\n",
        "words = word_tokenize(sentence_test)\n",
        "\n",
        "start = time.time()\n",
        "tagged_seq = Viterbi(words)\n",
        "print(tagged_seq)"
      ],
      "metadata": {
        "id": "dqZaFpcXD2Fp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}